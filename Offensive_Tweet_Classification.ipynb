{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "latest",
      "language": "python",
      "name": "latest"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "HW3_Best_Advanced.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0v_Azs9fhnVZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import spacy\n",
        "import string\n",
        "from nltk.util import ngrams\n",
        "from happyfuntokenizing import Tokenizer as potts\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn import preprocessing\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def potter_tokenizer(data):\n",
        "  tokenizer= potts()\n",
        "  return tokenizer.tokenize(data)\n",
        "\n",
        "# These 2 methods inspired by DonDuminda on Medium \"Sentiment Analysis on Customer Tweets (NLP)\"\n",
        "def remove_url(data):\n",
        "  tweet = re.sub('https?://[A-Za-z0-9./]+', '', data)\n",
        "  return tweet\n",
        "\n",
        "def remove_punc(data):\n",
        "  text = \"\".join([char for char in data if char not in string.punctuation])\n",
        "  return text"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLGtMGHWhKyn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = pd.read_csv('train.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SjOc-w2hW9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f8b51717-6745-4c9c-9a4c-2385486bb89f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>@USER She should ask a few native Americans wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16820</td>\n",
              "      <td>Amazon is investigating Chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62688</td>\n",
              "      <td>@USER Someone should'veTaken\" this piece of sh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43605</td>\n",
              "      <td>@USER @USER Obama wanted liberals &amp;amp; illega...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97670</td>\n",
              "      <td>@USER Liberals are all Kookoo !!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text  target\n",
              "0  86426  @USER She should ask a few native Americans wh...       1\n",
              "1  16820  Amazon is investigating Chinese employees who ...       0\n",
              "2  62688  @USER Someone should'veTaken\" this piece of sh...       1\n",
              "3  43605  @USER @USER Obama wanted liberals &amp; illega...       0\n",
              "4  97670                  @USER Liberals are all Kookoo !!!       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fufTZwRugk_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7044fed-de2e-4060-8549-c8c34a0a1253"
      },
      "source": [
        "bow = []\n",
        "for i in train['text']:\n",
        "    desc = remove_url(i)\n",
        "    desc = remove_punc(i)\n",
        "    tokens = potter_tokenizer(desc)\n",
        "    tokens = [token for token in tokens]\n",
        "    description =' '.join(tokens)\n",
        "    bow.append(description)\n",
        "bow[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'user she should ask a few native americans what their take on this is'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zxjIib2gpNY"
      },
      "source": [
        "train['text'] = bow"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nHyhdZjxbL5"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import torchtext.data as ttd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXChfD4CjX-t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5e2f3a4c-27a1-4555-d63a-a4c780e24e1c"
      },
      "source": [
        "df = train\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86426</td>\n",
              "      <td>user she should ask a few native americans wha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16820</td>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62688</td>\n",
              "      <td>user someone shouldvetaken this piece of shit ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43605</td>\n",
              "      <td>user user obama wanted liberals amp illegals t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97670</td>\n",
              "      <td>user liberals are all kookoo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                               text  target\n",
              "0  86426  user she should ask a few native americans wha...       1\n",
              "1  16820  amazon is investigating chinese employees who ...       0\n",
              "2  62688  user someone shouldvetaken this piece of shit ...       1\n",
              "3  43605  user user obama wanted liberals amp illegals t...       0\n",
              "4  97670                       user liberals are all kookoo       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Laiwn9vjjd7"
      },
      "source": [
        "# drop unnecessary columns\n",
        "df = df.drop([\"id\"], axis=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_0Qw2kyjsZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "400b64c0-5b88-4acb-89a0-96027f9a5213"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>user she should ask a few native americans wha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>amazon is investigating chinese employees who ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>user someone shouldvetaken this piece of shit ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>user user obama wanted liberals amp illegals t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>user liberals are all kookoo</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  user she should ask a few native americans wha...       1\n",
              "1  amazon is investigating chinese employees who ...       0\n",
              "2  user someone shouldvetaken this piece of shit ...       1\n",
              "3  user user obama wanted liberals amp illegals t...       0\n",
              "4                       user liberals are all kookoo       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKZPRzX3GhbM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d328812-42ce-466e-e5c2-6d8710f15de6"
      },
      "source": [
        "df['target'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    6220\n",
              "1    3126\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jES6beW-kW4D"
      },
      "source": [
        "df.columns = ['data', 'labels']"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iXLJ5umNHlm"
      },
      "source": [
        "df=df.sample(frac=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTIuKOi5kkkt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9d5da247-175b-472f-ae8a-0738b5142237"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6516</th>\n",
              "      <td>user wish to suck angel cookie</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8832</th>\n",
              "      <td>user user its god not god</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1133</th>\n",
              "      <td>user boycott the nfl</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6836</th>\n",
              "      <td>user can it kid</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7269</th>\n",
              "      <td>user user user user user user user user user u...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  labels\n",
              "6516                     user wish to suck angel cookie       0\n",
              "8832                          user user its god not god       0\n",
              "1133                               user boycott the nfl       0\n",
              "6836                                    user can it kid       0\n",
              "7269  user user user user user user user user user u...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb782Zji4dpS"
      },
      "source": [
        "df.to_csv('preprocessed.csv', index=False)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCkLpZqAk5Np"
      },
      "source": [
        "TEXT = ttd.Field(\n",
        "    sequential=True,\n",
        "    batch_first=True,\n",
        "    lower=False,\n",
        "    tokenize='spacy',\n",
        "    pad_first=True)\n",
        "\n",
        "LABEL = ttd.LabelField()\n",
        "\n",
        "dataset = ttd.TabularDataset(\n",
        "    path= 'preprocessed.csv',\n",
        "    format='csv',\n",
        "    skip_header=True,\n",
        "    fields=[('data', TEXT), ('label', LABEL)]\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqxnSM1G5JjH"
      },
      "source": [
        "import random\n",
        "train_dataset, test_dataset = dataset.split(split_ratio=0.95) # default is 0.7"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvwN3q1qtjb6"
      },
      "source": [
        "train_dataset, valid_dataset = train_dataset.split() # default is 0.7"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzqspeWmJIbC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2109d53e-bbb5-4cf9-ebd6-b2443caed402"
      },
      "source": [
        "print(f'Number of training examples: {len(train_dataset)}')\n",
        "print(f'Number of validation examples: {len(valid_dataset)}')\n",
        "print(f'Number of testing examples: {len(test_dataset)}')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 6215\n",
            "Number of validation examples: 2664\n",
            "Number of testing examples: 467\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ieo_C0AlvE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39eae5a1-9fa6-4f24-af54-83d60373c472"
      },
      "source": [
        "MAX_VOCAB_SIZE = 30000\n",
        "\n",
        "TEXT.build_vocab(train_dataset, \n",
        "                 max_size = MAX_VOCAB_SIZE, \n",
        "                 vectors = 'glove.6B.300d', \n",
        "                 unk_init = torch.Tensor.normal_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:35, 2.18MB/s]                          \n",
            "100%|█████████▉| 399316/400000 [00:51<00:00, 7496.05it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTkkNIV4iYrN"
      },
      "source": [
        "LABEL.build_vocab(train_dataset)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lew5Hi_klyi5"
      },
      "source": [
        "vocab_text = TEXT.vocab\n",
        "vocab_label = LABEL.vocab"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM30vqWqinab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01dac8b4-220f-44eb-a9fa-c677f248854e"
      },
      "source": [
        "len(vocab_text)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE2Ud9bvBZLm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf929bc-087c-414e-efe6-ee2efd5a61ac"
      },
      "source": [
        "vocab_label.stoi"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>, {'0': 0, '1': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ni84WH6UBdbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40eb887-d99a-4ac3-8696-53abed2b5048"
      },
      "source": [
        "vocab_label.itos"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9fgCUSA7ju4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a019a31-ff05-447d-f074-e3ac52937199"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXiLOhEXmrNs"
      },
      "source": [
        "train_iter, valid_iter, test_iter = ttd.BucketIterator.splits((train_dataset,valid_dataset,test_dataset), \n",
        "                              sort_key=lambda x: len(x.data),\n",
        "                              batch_sizes=(64,64,64), \n",
        "                              device=device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p67zN6Oy8kOn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f6d56d-d6cd-43f6-da4a-b26339ce4d6c"
      },
      "source": [
        "for batch in train_iter:\n",
        "  print(\"inputs:\", batch.data, batch.data.shape)\n",
        "  print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[    1,     1,     1,  ...,  4310,  1291, 13625],\n",
            "        [    1,     1,     1,  ...,  1999,   175,   471],\n",
            "        [    1,     1,     1,  ...,   497,  4303,    19],\n",
            "        ...,\n",
            "        [    1,     1,     1,  ...,  5784,  4848,   120],\n",
            "        [    1,     1,     1,  ...,   131,     3,   134],\n",
            "        [    1,     1,     1,  ...,    65,   234, 11235]], device='cuda:0') torch.Size([64, 61])\n",
            "targets: tensor([0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
            "        1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
            "        1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0], device='cuda:0') shape: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGgBYOHLm4P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b7f4df-5db6-46cb-e304-09bef187b180"
      },
      "source": [
        "for batch in valid_iter:\n",
        "  print(\"inputs:\", batch.data, batch.data.shape)\n",
        "  print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([[   2,    2,  607, 1466],\n",
            "        [   2, 9518,  224,  328],\n",
            "        [   2,   38,    0,  180],\n",
            "        [   2, 1398,    8,  220],\n",
            "        [   2,   16,    4,  320],\n",
            "        [   2, 4246,    3,  678],\n",
            "        [   2,   13,    4,   19],\n",
            "        [   2,    0,  110,    0],\n",
            "        [   2,  322,   37,    0],\n",
            "        [   2,    2,    2,  467],\n",
            "        [   2,   95,  183,  305],\n",
            "        [   2,   16,    4,  406],\n",
            "        [   2,   13,    4, 1918],\n",
            "        [   2,   21,   54,   32],\n",
            "        [   2,  180,   70, 2262],\n",
            "        [   2,  149,   13,    4],\n",
            "        [   2,    2,  205,  179],\n",
            "        [   2,    6,  957,   18],\n",
            "        [   2,  228,  110,   19],\n",
            "        [   1,    2,  274,  222],\n",
            "        [   1,    2,  670,  806],\n",
            "        [   1,    2,   21, 9343],\n",
            "        [   1,    2,    2,    0],\n",
            "        [   1,    2,  257,  110],\n",
            "        [   1,    2,  712,  665],\n",
            "        [   1,    2,   53,    0],\n",
            "        [   1,    2,  294,   53],\n",
            "        [   1,    2,    8,  669],\n",
            "        [   1,   47,   41,   19],\n",
            "        [   1,    2,    0,   41],\n",
            "        [   1,    2, 1943,   19],\n",
            "        [   1,    2,   41,  491],\n",
            "        [   1,    2,  209,  827],\n",
            "        [   1,    2,  754,  180],\n",
            "        [   1,    2,  274, 1245],\n",
            "        [   1,    2,  294,  663],\n",
            "        [   1,    2,  160,  654],\n",
            "        [   1,    2,    0,  223],\n",
            "        [   1,    2,    2, 1721],\n",
            "        [   1,    2,  160,    0],\n",
            "        [   1,    2,  754,  110],\n",
            "        [   1,    2,    8,  669],\n",
            "        [   1,    2,  339,   28],\n",
            "        [   1, 6301,    4, 3164],\n",
            "        [   1,    2, 1648, 1077],\n",
            "        [   1,    2,   70, 1403],\n",
            "        [   1,    2,    2, 1149],\n",
            "        [   1,    2, 1600,    0],\n",
            "        [   1,    2,  449,    0],\n",
            "        [   1,    2,   16,    4],\n",
            "        [   1,    2,   88, 6814],\n",
            "        [   1,    2, 8682, 3307],\n",
            "        [   1,    1,    2,  384],\n",
            "        [   1,    1,    2,    0],\n",
            "        [   1,    1,    2,  697],\n",
            "        [   1,    1,    2, 9295],\n",
            "        [   1,    1,    2,  514],\n",
            "        [   1,    1,    2,  472],\n",
            "        [   1,    1,    2,  472],\n",
            "        [   1,    1,    2,  956],\n",
            "        [   1,    1,    2, 7231],\n",
            "        [   1,    1,    2,    0],\n",
            "        [   1,    1,    2,  501],\n",
            "        [   1,    1,    2, 1910]], device='cuda:0') torch.Size([64, 4])\n",
            "targets: tensor([0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
            "        1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
            "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0], device='cuda:0') shape: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beGVBMlwV0dK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17793892-0f18-4fc0-90b8-4290ad68ba63"
      },
      "source": [
        "for batch in test_iter:\n",
        "  print(\"inputs:\", batch.data[0], batch.data[0].shape)\n",
        "  print(\"targets:\",batch.label, \"shape:\", batch.label.shape)\n",
        "  break"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs: tensor([   2,  101,   15,   49, 1037,    8,  898,  133], device='cuda:0') torch.Size([8])\n",
            "targets: tensor([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
            "        0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
            "        0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1], device='cuda:0') shape: torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTdqSCmwfRNp"
      },
      "source": [
        "# Defining the model\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate):\n",
        "    super(RNN, self).__init__()\n",
        "    self.V = n_vocab\n",
        "    self.D = embed_dim\n",
        "    self.M = n_hidden\n",
        "    self.K = n_outputs\n",
        "    self.L = n_rnnlayers\n",
        "    self.num_diections= bidirectional\n",
        "    self.dropout_rate=dropout_rate\n",
        "    \n",
        "    self.embed = nn.Embedding(self.V, self.D)\n",
        "    \n",
        "    self.rnn = nn.LSTM(\n",
        "        input_size=self.D,\n",
        "        hidden_size=self.M,\n",
        "        num_layers=self.L,\n",
        "        bidirectional=self.num_diections,\n",
        "        dropout= self.dropout_rate,\n",
        "        batch_first=True)\n",
        "    \n",
        "    self.fc = nn.Linear(self.M *2 , self.K)\n",
        "\n",
        "    self.dropout= nn.Dropout(self.dropout_rate)\n",
        "  \n",
        "  def forward(self, X):\n",
        "    h0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
        "    c0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
        "\n",
        "    embedding = self.embed(X)   \n",
        "    embedding= self.dropout(embedding) \n",
        "\n",
        "    # get RNN unit output\n",
        "    output, (hidden,cell) = self.rnn(embedding, (h0, c0))\n",
        "\n",
        "    output, _ = torch.max(output, 1)\n",
        "    output= self.dropout(output)\n",
        "    output = self.fc(output)\n",
        "    return output"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNh5F8I8oBRt"
      },
      "source": [
        "n_vocab = len(TEXT.vocab)\n",
        "embed_dim = 200\n",
        "n_hidden = 256 \n",
        "n_rnnlayers = 2\n",
        "n_outputs =2\n",
        "bidirectional = True \n",
        "dropout_rate = 0.5 \n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi6O8d9E4WON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4678b73a-9875-4b2c-933d-095fe0e1327e"
      },
      "source": [
        "model = RNN(n_vocab, embed_dim, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
        "model.to(device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embed): Embedding(13692, 200)\n",
              "  (rnn): LSTM(200, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
              "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JWyeS3DwKpj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "338752b8-b9f2-4905-eda5-a1036d17d42f"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  print(name, param.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embed.weight torch.Size([13692, 200])\n",
            "rnn.weight_ih_l0 torch.Size([1024, 200])\n",
            "rnn.weight_hh_l0 torch.Size([1024, 256])\n",
            "rnn.bias_ih_l0 torch.Size([1024])\n",
            "rnn.bias_hh_l0 torch.Size([1024])\n",
            "rnn.weight_ih_l0_reverse torch.Size([1024, 200])\n",
            "rnn.weight_hh_l0_reverse torch.Size([1024, 256])\n",
            "rnn.bias_ih_l0_reverse torch.Size([1024])\n",
            "rnn.bias_hh_l0_reverse torch.Size([1024])\n",
            "rnn.weight_ih_l1 torch.Size([1024, 512])\n",
            "rnn.weight_hh_l1 torch.Size([1024, 256])\n",
            "rnn.bias_ih_l1 torch.Size([1024])\n",
            "rnn.bias_hh_l1 torch.Size([1024])\n",
            "rnn.weight_ih_l1_reverse torch.Size([1024, 512])\n",
            "rnn.weight_hh_l1_reverse torch.Size([1024, 256])\n",
            "rnn.bias_ih_l1_reverse torch.Size([1024])\n",
            "rnn.bias_hh_l1_reverse torch.Size([1024])\n",
            "fc.weight torch.Size([2, 512])\n",
            "fc.bias torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpRh0XOQ5QkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab94f76f-149d-48a2-9d6f-f94cedf98335"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "print(pretrained_embeddings.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([13692, 300])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAHviEZN5wL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b422bfbb-f342-4eed-92ed-af6e13e9741d"
      },
      "source": [
        "unk_idx = TEXT.vocab.stoi[TEXT.unk_token]\n",
        "pad_idx = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model.embed.weight.data[unk_idx] = torch.zeros(embed_dim)\n",
        "model.embed.weight.data[pad_idx] = torch.zeros(embed_dim)\n",
        "\n",
        "print(model.embed.weight.data)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.9839, -0.0575, -0.9533,  ..., -0.5240, -0.2401,  0.7062],\n",
            "        ...,\n",
            "        [-0.3671,  1.2739,  1.0778,  ..., -0.4097, -0.6820,  0.9246],\n",
            "        [ 0.1456, -1.0601,  0.1977,  ...,  1.4106, -0.4894, -0.2281],\n",
            "        [-2.2618, -0.3834, -0.5456,  ...,  0.7737, -0.8125, -0.6338]],\n",
            "       device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "025OmwnxOUiC"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BjQYSeyRSxj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c6187a-5b85-4cec-a22e-2aa554bf4574"
      },
      "source": [
        "learning_rate = 0.005\n",
        "epochs = 100\n",
        "# STEP 5: INSTANTIATE LOSS CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Freeze embedding Layer\n",
        "\n",
        "#freeze embeddings\n",
        "model.embed.weight.requires_grad  = False\n",
        "\n",
        "# STEP 7: TRAIN THE MODEL\n",
        "\n",
        "train_losses= np.zeros(epochs)\n",
        "valid_losses= np.zeros(epochs)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  t0= datetime.now()\n",
        "  train_loss=[]\n",
        "  \n",
        "  model.train()\n",
        "  for batch in train_iter:\n",
        "   \n",
        "    # forward pass\n",
        "    output= model(batch.data)\n",
        "    loss=criterion(output,batch.label)\n",
        "\n",
        "    # set gradients to zero \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss.append(loss.item())\n",
        "  \n",
        "  train_loss=np.mean(train_loss)\n",
        "      \n",
        "  valid_loss=[]\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in valid_iter:\n",
        " \n",
        "      # forward pass\n",
        "      output= model(batch.data)\n",
        "      loss=criterion(output,batch.label)\n",
        "      \n",
        "      valid_loss.append(loss.item())\n",
        "\n",
        "    valid_loss=np.mean(valid_loss)\n",
        "  \n",
        "  # save Losses\n",
        "  train_losses[epoch]= train_loss\n",
        "  valid_losses[epoch]= valid_loss\n",
        "  dt= datetime.now()-t0\n",
        "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100, Train Loss: 0.6426    Valid Loss: 0.6058, Duration: 0:00:03.297271\n",
            "Epoch 2/100, Train Loss: 0.6013    Valid Loss: 0.5448, Duration: 0:00:03.150546\n",
            "Epoch 3/100, Train Loss: 0.5777    Valid Loss: 0.5416, Duration: 0:00:03.180831\n",
            "Epoch 4/100, Train Loss: 0.5605    Valid Loss: 0.5354, Duration: 0:00:03.180491\n",
            "Epoch 5/100, Train Loss: 0.5451    Valid Loss: 0.5491, Duration: 0:00:03.136622\n",
            "Epoch 6/100, Train Loss: 0.5361    Valid Loss: 0.5449, Duration: 0:00:03.149949\n",
            "Epoch 7/100, Train Loss: 0.5246    Valid Loss: 0.5521, Duration: 0:00:03.178646\n",
            "Epoch 8/100, Train Loss: 0.5160    Valid Loss: 0.5641, Duration: 0:00:03.192994\n",
            "Epoch 9/100, Train Loss: 0.5158    Valid Loss: 0.5712, Duration: 0:00:03.206887\n",
            "Epoch 10/100, Train Loss: 0.4946    Valid Loss: 0.6089, Duration: 0:00:03.144724\n",
            "Epoch 11/100, Train Loss: 0.4981    Valid Loss: 0.5665, Duration: 0:00:03.179806\n",
            "Epoch 12/100, Train Loss: 0.4880    Valid Loss: 0.5586, Duration: 0:00:03.161591\n",
            "Epoch 13/100, Train Loss: 0.4899    Valid Loss: 0.5726, Duration: 0:00:03.152480\n",
            "Epoch 14/100, Train Loss: 0.4724    Valid Loss: 0.5787, Duration: 0:00:03.168670\n",
            "Epoch 15/100, Train Loss: 0.4671    Valid Loss: 0.6546, Duration: 0:00:03.161800\n",
            "Epoch 16/100, Train Loss: 0.4564    Valid Loss: 0.6901, Duration: 0:00:03.161200\n",
            "Epoch 17/100, Train Loss: 0.4686    Valid Loss: 0.5592, Duration: 0:00:03.140511\n",
            "Epoch 18/100, Train Loss: 0.4477    Valid Loss: 0.6161, Duration: 0:00:03.190951\n",
            "Epoch 19/100, Train Loss: 0.4575    Valid Loss: 0.6330, Duration: 0:00:03.153582\n",
            "Epoch 20/100, Train Loss: 0.4397    Valid Loss: 0.6149, Duration: 0:00:03.155288\n",
            "Epoch 21/100, Train Loss: 0.4473    Valid Loss: 0.6538, Duration: 0:00:03.140846\n",
            "Epoch 22/100, Train Loss: 0.4356    Valid Loss: 0.6572, Duration: 0:00:03.135974\n",
            "Epoch 23/100, Train Loss: 0.4378    Valid Loss: 0.7427, Duration: 0:00:03.136085\n",
            "Epoch 24/100, Train Loss: 0.4352    Valid Loss: 0.6555, Duration: 0:00:03.110357\n",
            "Epoch 25/100, Train Loss: 0.4301    Valid Loss: 0.7140, Duration: 0:00:03.143266\n",
            "Epoch 26/100, Train Loss: 0.4279    Valid Loss: 0.7065, Duration: 0:00:03.208323\n",
            "Epoch 27/100, Train Loss: 0.4198    Valid Loss: 0.7306, Duration: 0:00:03.190764\n",
            "Epoch 28/100, Train Loss: 0.4151    Valid Loss: 0.7022, Duration: 0:00:03.186091\n",
            "Epoch 29/100, Train Loss: 0.4224    Valid Loss: 0.7281, Duration: 0:00:03.192661\n",
            "Epoch 30/100, Train Loss: 0.4232    Valid Loss: 0.7072, Duration: 0:00:03.171922\n",
            "Epoch 31/100, Train Loss: 0.4430    Valid Loss: 0.6466, Duration: 0:00:03.105401\n",
            "Epoch 32/100, Train Loss: 0.4135    Valid Loss: 0.7024, Duration: 0:00:03.154231\n",
            "Epoch 33/100, Train Loss: 0.4379    Valid Loss: 0.6971, Duration: 0:00:03.117390\n",
            "Epoch 34/100, Train Loss: 0.4339    Valid Loss: 0.6911, Duration: 0:00:03.153263\n",
            "Epoch 35/100, Train Loss: 0.4209    Valid Loss: 0.7562, Duration: 0:00:03.129052\n",
            "Epoch 36/100, Train Loss: 0.4204    Valid Loss: 0.8499, Duration: 0:00:03.190058\n",
            "Epoch 37/100, Train Loss: 0.4317    Valid Loss: 0.6535, Duration: 0:00:03.207971\n",
            "Epoch 38/100, Train Loss: 0.4370    Valid Loss: 0.6906, Duration: 0:00:03.139796\n",
            "Epoch 39/100, Train Loss: 0.4267    Valid Loss: 0.7216, Duration: 0:00:03.164395\n",
            "Epoch 40/100, Train Loss: 0.4274    Valid Loss: 0.6194, Duration: 0:00:03.180593\n",
            "Epoch 41/100, Train Loss: 0.4284    Valid Loss: 0.6696, Duration: 0:00:03.209458\n",
            "Epoch 42/100, Train Loss: 0.4313    Valid Loss: 0.7061, Duration: 0:00:03.154940\n",
            "Epoch 43/100, Train Loss: 0.4410    Valid Loss: 0.7085, Duration: 0:00:03.153152\n",
            "Epoch 44/100, Train Loss: 0.4198    Valid Loss: 0.7961, Duration: 0:00:03.191751\n",
            "Epoch 45/100, Train Loss: 0.4396    Valid Loss: 0.7567, Duration: 0:00:03.186172\n",
            "Epoch 46/100, Train Loss: 0.4285    Valid Loss: 0.7333, Duration: 0:00:03.171401\n",
            "Epoch 47/100, Train Loss: 0.4354    Valid Loss: 0.8115, Duration: 0:00:03.184431\n",
            "Epoch 48/100, Train Loss: 0.4149    Valid Loss: 0.7817, Duration: 0:00:03.162676\n",
            "Epoch 49/100, Train Loss: 0.4187    Valid Loss: 0.8691, Duration: 0:00:03.147150\n",
            "Epoch 50/100, Train Loss: 0.4230    Valid Loss: 0.9149, Duration: 0:00:03.157438\n",
            "Epoch 51/100, Train Loss: 0.4269    Valid Loss: 0.8081, Duration: 0:00:03.165942\n",
            "Epoch 52/100, Train Loss: 0.4168    Valid Loss: 0.8223, Duration: 0:00:03.165978\n",
            "Epoch 53/100, Train Loss: 0.4254    Valid Loss: 0.8618, Duration: 0:00:03.174475\n",
            "Epoch 54/100, Train Loss: 0.4152    Valid Loss: 0.8176, Duration: 0:00:03.156160\n",
            "Epoch 55/100, Train Loss: 0.4178    Valid Loss: 0.8055, Duration: 0:00:03.204399\n",
            "Epoch 56/100, Train Loss: 0.4155    Valid Loss: 0.7893, Duration: 0:00:03.205323\n",
            "Epoch 57/100, Train Loss: 0.4198    Valid Loss: 0.7637, Duration: 0:00:03.169518\n",
            "Epoch 58/100, Train Loss: 0.4156    Valid Loss: 0.8189, Duration: 0:00:03.145274\n",
            "Epoch 59/100, Train Loss: 0.4285    Valid Loss: 0.8044, Duration: 0:00:03.171880\n",
            "Epoch 60/100, Train Loss: 0.4222    Valid Loss: 0.7902, Duration: 0:00:03.176519\n",
            "Epoch 61/100, Train Loss: 0.4193    Valid Loss: 0.7941, Duration: 0:00:03.136704\n",
            "Epoch 62/100, Train Loss: 0.4175    Valid Loss: 0.8694, Duration: 0:00:03.165474\n",
            "Epoch 63/100, Train Loss: 0.4206    Valid Loss: 0.7943, Duration: 0:00:03.160744\n",
            "Epoch 64/100, Train Loss: 0.4050    Valid Loss: 0.8415, Duration: 0:00:03.139194\n",
            "Epoch 65/100, Train Loss: 0.4197    Valid Loss: 0.8824, Duration: 0:00:03.163350\n",
            "Epoch 66/100, Train Loss: 0.4086    Valid Loss: 0.7988, Duration: 0:00:03.187231\n",
            "Epoch 67/100, Train Loss: 0.4247    Valid Loss: 0.9493, Duration: 0:00:03.155373\n",
            "Epoch 68/100, Train Loss: 0.4114    Valid Loss: 0.8589, Duration: 0:00:03.180136\n",
            "Epoch 69/100, Train Loss: 0.4267    Valid Loss: 0.8582, Duration: 0:00:03.198495\n",
            "Epoch 70/100, Train Loss: 0.4181    Valid Loss: 0.8425, Duration: 0:00:03.165269\n",
            "Epoch 71/100, Train Loss: 0.4127    Valid Loss: 0.7992, Duration: 0:00:03.116138\n",
            "Epoch 72/100, Train Loss: 0.4211    Valid Loss: 0.7844, Duration: 0:00:03.153339\n",
            "Epoch 73/100, Train Loss: 0.4142    Valid Loss: 0.8103, Duration: 0:00:03.170954\n",
            "Epoch 74/100, Train Loss: 0.4173    Valid Loss: 0.8379, Duration: 0:00:03.171977\n",
            "Epoch 75/100, Train Loss: 0.4155    Valid Loss: 0.9086, Duration: 0:00:03.184685\n",
            "Epoch 76/100, Train Loss: 0.4282    Valid Loss: 0.8620, Duration: 0:00:03.166751\n",
            "Epoch 77/100, Train Loss: 0.4118    Valid Loss: 0.8736, Duration: 0:00:03.147852\n",
            "Epoch 78/100, Train Loss: 0.4266    Valid Loss: 0.8999, Duration: 0:00:03.174035\n",
            "Epoch 79/100, Train Loss: 0.4298    Valid Loss: 0.8167, Duration: 0:00:03.161795\n",
            "Epoch 80/100, Train Loss: 0.4215    Valid Loss: 0.8573, Duration: 0:00:03.171216\n",
            "Epoch 81/100, Train Loss: 0.4273    Valid Loss: 0.8254, Duration: 0:00:03.191635\n",
            "Epoch 82/100, Train Loss: 0.4194    Valid Loss: 0.7892, Duration: 0:00:03.112030\n",
            "Epoch 83/100, Train Loss: 0.4154    Valid Loss: 0.8557, Duration: 0:00:03.100842\n",
            "Epoch 84/100, Train Loss: 0.4228    Valid Loss: 0.9057, Duration: 0:00:03.102552\n",
            "Epoch 85/100, Train Loss: 0.4268    Valid Loss: 0.8646, Duration: 0:00:03.178625\n",
            "Epoch 86/100, Train Loss: 0.4202    Valid Loss: 0.8180, Duration: 0:00:03.179725\n",
            "Epoch 87/100, Train Loss: 0.4290    Valid Loss: 0.9132, Duration: 0:00:03.177874\n",
            "Epoch 88/100, Train Loss: 0.4222    Valid Loss: 0.8472, Duration: 0:00:03.150741\n",
            "Epoch 89/100, Train Loss: 0.4262    Valid Loss: 0.8237, Duration: 0:00:03.133708\n",
            "Epoch 90/100, Train Loss: 0.4145    Valid Loss: 0.8702, Duration: 0:00:03.175963\n",
            "Epoch 91/100, Train Loss: 0.4318    Valid Loss: 0.8871, Duration: 0:00:03.155984\n",
            "Epoch 92/100, Train Loss: 0.4375    Valid Loss: 0.8269, Duration: 0:00:03.168539\n",
            "Epoch 93/100, Train Loss: 0.4218    Valid Loss: 0.9227, Duration: 0:00:03.141543\n",
            "Epoch 94/100, Train Loss: 0.4371    Valid Loss: 0.8321, Duration: 0:00:03.174784\n",
            "Epoch 95/100, Train Loss: 0.4321    Valid Loss: 0.8856, Duration: 0:00:03.178123\n",
            "Epoch 96/100, Train Loss: 0.4375    Valid Loss: 0.8822, Duration: 0:00:03.190929\n",
            "Epoch 97/100, Train Loss: 0.4549    Valid Loss: 0.8363, Duration: 0:00:03.185751\n",
            "Epoch 98/100, Train Loss: 0.4486    Valid Loss: 0.7744, Duration: 0:00:03.175317\n",
            "Epoch 99/100, Train Loss: 0.4581    Valid Loss: 0.7107, Duration: 0:00:03.153637\n",
            "Epoch 100/100, Train Loss: 0.4436    Valid Loss: 0.8330, Duration: 0:00:03.190257\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGFsntvqpj4B"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      output=model(batch.data)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      correct+= (batch.label==indices).sum().item()\n",
        "      total += batch.label.shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9viF8Lxpnpm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9279e86-f496-47d5-e119-17116edd92ac"
      },
      "source": [
        "train_acc = get_accuracy(train_iter, model)\n",
        "valid_acc = get_accuracy(valid_iter, model)\n",
        "test_acc = get_accuracy(test_iter ,model)\n",
        "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.7947,\t Valid acc: 0.7511,\t Test acc: 0.7238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWLx1vJtWbxN"
      },
      "source": [
        "def get_predictions(test_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in test_iter:\n",
        "      \n",
        "      output=model(batch.data)\n",
        "      _,indices = torch.max(output,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,batch.label.cpu().numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdXRTci2fGrh"
      },
      "source": [
        "y_test, predictions=get_predictions(test_iter, model)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ElmV8QX95t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3de53de-ec5d-43fa-dbcd-335dd4f0530e"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "confusion_matrix(y_test, predictions)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[289,   4],\n",
              "       [125,  49]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZ7sxObSfGrn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8c5b23-45ff-4e4a-da22-a98dcbe91a1d"
      },
      "source": [
        "print(classification_report(y_test, predictions))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.99      0.82       293\n",
            "         1.0       0.92      0.28      0.43       174\n",
            "\n",
            "    accuracy                           0.72       467\n",
            "   macro avg       0.81      0.63      0.62       467\n",
            "weighted avg       0.78      0.72      0.67       467\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFLt5nDeWkxt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0386275a-2150-4e6d-d215-09b18c1cf155"
      },
      "source": [
        "cm=confusion_matrix(y_test,predictions)\n",
        "cm"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[289,   4],\n",
              "       [125,  49]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    }
  ]
}